# 05. Concurrency Primitives

## Concurrency in Beam

Erlang is all about writing highly available systems — systems that run forever and are always able to meaningfully respond to client requests. To make your system highly available, you have to tackle the following challenges:

* Fault-tolerance — Minimize, isolate, and recover from the effects of runtime errors.
* Scalability — Handle a load increase by adding more hardware resources without changing or redeploying the code.
* Distribution — Run your system on multiple machines so that others can take over if one machine crashes.

<!-- livebook:{"break_markdown":true} -->

* By default, BEAM uses as many schedulers as there are CPU cores available
* Each scheduler runs in its own thread, and the entire VM runs in a single OS process.
* Data in Elixir is immutable. To keep it alive, you have to hold on to it, constantly passing the result of one function to another. A process can be considered a container of this data — a place where an immutable structure is stored and kept alive for a longer time, possibly forever.

## Working with processes

**Concurrency vs. parallelism**

It's important to realize that concurrency doesn't necessarily imply parallelism. Two concurrent things have independent execution contexts, but this doesn't mean they will run in parallel. If you run two CPU-bound concurrent tasks and you only have one CPU core, parallel execution can't happen. You can achieve parallelism by adding more CPU cores and relying on an efficient concurrent framework. But you should be aware that concurrency itself doesn't necessarily speed things up.

```elixir
run_query = fn query_def ->
  Process.sleep(2000)
  "#{query_def} result"
end
```

Here, the code sleeps for two seconds to simulate a long-running operation. When you call the run_query lambda, the shell is blocked until the lambda is done. Consequently, if you run five queries, it will take 10 seconds to get all the results:

```elixir
Enum.map(1..5, &run_query.("query #{&1}"))
```

To create a process, you can use the auto-imported `spawn/1` function. After the process is created, spawn immediately returns, and the caller process's execution continues

```elixir
async_query = fn query_def ->
  spawn(fn -> IO.puts(run_query.(query_def)) end)
end
```

```elixir
Enum.each(1..5, &async_query.("query #{&1}"))
```

The call to `Enum.each/2` now returns immediately (in the first sequential version you had to wait 10 seconds for it to finish). Moreover, all the results are printed at practically the same time, two seconds later, which is a five-fold improvement over the sequential version. This happens because you run each computation concurrently.

Also note that because processes run concurrently, the order of execution isn't guaranteed.

## Message passing

When process A wants process B to do something, it sends an asynchronous message to B. The content of the message is an Elixir term — anything you can store in a variable. Sending a message amounts to storing it into the receiver’s mailbox. The caller then continues with its own execution, and the receiver can pull the message in at any time and process it in some way. Because processes can’t share memory, a message is deep-copied when it’s sent.

The process mailbox is a FIFO queue limited only by the available memory. The receiver consumes messages in the order received, and a message can be removed from the queue only if it's consumed.

Use `send` from `Kernel` to sending a message:

```elixir
send(self(), "World")
```

```elixir
receive do
  message -> IO.puts("Hello, #{message}")
after
  5000 -> IO.puts("message not received")
end
```

The receive expression works as follows:

1. Take the first message from the mailbox.
2. Try to match it against any of the provided patterns, going from top to bottom.
3. If a pattern matches the message, run the corresponding code.
4. If no pattern matches, put the message back into the mailbox at the same position it originally occupied. Then try the next message.
5. If there are no more messages in the queue, wait for a new one to arrive. When a new message arrives, start from step 1, inspecting the first message in the mailbox.
6. If the after clause is specified and no message is matched in the given amount of time, run the code from the after block.

## Collecting query resuts

You'll run queries in separate processes and print them to the screen from those processe

```elixir
run_query = fn query_def ->
  Process.sleep(2000)
  "#{query_def} result"
end

async_query = fn query_def ->
  caller = self()

  spawn(fn ->
    send(caller, {:query_result, run_query.(query_def)})
  end)
end
```

```elixir
Enum.each(1..5, &async_query.("query #{&1}"))
```

This runs all the queries concurrently, and the result is stored in the mailbox of the caller process. In this case, this is the shell (`iex`) process.    
Notice that the caller process is neither blocked nor interrupted while receiving messages. Sending a message doesn’t disturb the receiving process in any way. If the process is performing computations, it continues to do so. The only thing affected is the content of the receiving process’s mailbox. Messages remain in the mailbox until they’re consumed or the process terminates.

```elixir
get_result = fn ->
  receive do
    {:query_result, result} -> result
  end
end
```

```elixir
results = Enum.map(1..5, fn _ -> get_result.() end)
```

## Server process

A server process is an informal name for a process that runs for a long time (or forever) and can handle various requests (messages). o make a process run forever, you have to use endless tail recursion.

```elixir
defmodule DatabaseServer do
  # * Interface Functions

  def start do
    spawn(&loop/0)
  end

  def run_async(server_pid, query_def) do
    send(server_pid, {:run_query, self(), query_def})
  end

  def get_result do
    receive do
      {:query_result, result} -> result
    after
      5000 -> {:error, :timeout}
    end
  end

  # * Implementation Functions

  defp loop do
    receive do
      {:run_query, caller, query_def} ->
        send(caller, {:query_result, run_query(query_def)})
    end

    loop()
  end

  defp run_query(query_def) do
    Process.sleep(2000)
    "#{query_def} result"
  end
end
```

This loop isn’t CPU-intensive. Waiting for a message puts the process in a suspended state and doesn’t waste CPU cycles.

<!-- livebook:{"break_markdown":true} -->

Notice that functions in this module run in different processes. The function start/0 is called by clients and runs in a client process. The private function loop/0 runs in the server process. It’s perfectly normal to have different functions from the same module running in different processes — there’s no special relationship between modules and processes. A module is just a collection of functions, and these functions can be invoked in any process.

```elixir
server_pid = DatabaseServer.start()
```

```elixir
DatabaseServer.run_async(server_pid, "query 1")
DatabaseServer.get_result()
```

```elixir
DatabaseServer.run_async(server_pid, "query 2")
DatabaseServer.get_result()
```

## Server process are sequential

It’s important to realize that a server process is internally sequential. It runs a loop that processes one message at a time. Thus, if you issue five asynchronous query requests to a single server process, they will be handled one by one, and the result of the last query will come after 10 seconds.

<!-- livebook:{"break_markdown":true} -->

If you need to run in parallel, you can run multiple processes and balance the messages to thoses processes already created

```elixir
pool = Enum.map(1..100, fn _ -> DatabaseServer.start() end)
```

Here you create 100 database-server processes and store their pids in a list. You may think that 100 processes is a lot, but recall that processes are lightweight. They take up a small amount of memory (~2 KB) and are created very quickly (in a few microseconds). Furthermore, because all of these processes wait for a message, they’re effectively idle and don’t waste CPU time.

<!-- livebook:{"break_markdown":true} -->

To run a query you need to get a process randomly. This is not efficient at all, but will be getting this done.

```elixir
Enum.each(
  1..5,
  fn query_def ->
    server_pid = Enum.at(pool, :rand.uniform(100) - 1)
    DatabaseServer.run_async(server_pid, query_def)
  end
)
```

```elixir
Enum.map(1..5, fn _ -> DatabaseServer.get_result() end)
```

## Keeping a process state

To keep some state during the process loop, just pass the argument to function loop and keep on it.

<!-- livebook:{"break_markdown":true} -->

<!-- livebook:{"force_markdown":true} -->

```elixir
def start do
  spawn(fn ->
    initial_state = State.new()   
    loop(initial_state) # initialize state    
  end)
end

defp loop(state) do # Receive state 
  ...
  loop(state) # Keep state on loop
end
```

## Complex state

```elixir
defmodule TodoList do
  defstruct auto_id: 1, entries: %{}

  def new(entries \\ []) do
    Enum.reduce(
      entries,
      %TodoList{},
      fn entry, todo_list_acc ->
        add_entry(todo_list_acc, entry)
      end
    )
  end

  def add_entry(todo_list, entry) do
    entry = Map.put(entry, :id, todo_list.auto_id)

    new_entries =
      Map.put(
        todo_list.entries,
        todo_list.auto_id,
        entry
      )

    %TodoList{todo_list | entries: new_entries, auto_id: todo_list.auto_id + 1}
  end

  def entries(todo_list, date) do
    todo_list.entries
    |> Stream.filter(fn {_, entry} -> entry.date == date end)
    |> Enum.map(fn {_, entry} -> entry end)
  end

  def update_entry(todo_list, entry_id, updater_fun) do
    case Map.fetch(todo_list.entries, entry_id) do
      :error ->
        todo_list

      {:ok, old_entry} ->
        old_entry_id = old_entry.id
        new_entry = %{id: ^old_entry_id} = updater_fun.(old_entry)
        new_entries = Map.put(todo_list.entries, new_entry.id, new_entry)
        %TodoList{todo_list | entries: new_entries}
    end
  end

  def delete_entry(todo_list, entry_id) do
    new_entries = Map.delete(todo_list.entries, entry_id)
    %TodoList{todo_list | entries: new_entries}
  end
end
```

```elixir
defmodule TodoServer do
  # API 

  def start do
    spawn(fn -> loop(TodoList.new()) end)
  end

  def add_entry(todo_server, new_entry) do
    send(todo_server, {:add_entry, new_entry})
  end

  def entries(todo_server, date) do
    send(todo_server, {:entries, self(), date})

    receive do
      {:todo_entries, entries} -> entries
    after
      5000 -> {:error, :timeout}
    end
  end

  def update_entry(todo_server, id, update_fn) do
    send(todo_server, {:update_entry, id, update_fn})
  end

  def delete_entry(todo_server, id) do
    send(todo_server, {:delete_entry, id})
  end

  # Callbacks

  defp loop(todo_list) do
    new_todo_list =
      receive do
        message -> process_message(todo_list, message)
      end

    loop(new_todo_list)
  end

  defp process_message(todo_list, {:add_entry, new_entry}) do
    TodoList.add_entry(todo_list, new_entry)
  end

  defp process_message(todo_list, {:entries, caller, date}) do
    # Sends the response to the caller
    send(caller, {:todo_entries, TodoList.entries(todo_list, date)})
    # The state remains unchanged.
    todo_list
  end

  defp process_message(todo_list, {:update_entry, id, update_fn}) do
    TodoList.update_entry(todo_list, id, update_fn)
  end

  defp process_message(todo_list, {:delete_entry, id}) do
    TodoList.delete_entry(todo_list, id)
  end
end
```

### CONCURRENCY VS FUNCTIONAL APPROACH

A process that keeps mutable state can be regarded as a kind of mutable data structure. You can start the server and then perform various requests on it. But you shouldn't abuse processes to avoid using the functional approach of transforming immutable data.

The data should be modeled using pure functional abstractions, just as you did with TodoList. A pure functional data structure provides many benefits, such as integrity and atomicity. Furthermore, it can be reused in various contexts and tested independently.

## Registered processes

To processes communicate each other, they must to know the `pid`. A `pid` is a _process identifier_ that tell us the address of the process. You can given a name to this process to and call it with this name.

```elixir
Process.register(self(), :some_name)
```

```elixir
send(:some_name, :msg)
```

```elixir
receive do
  msg -> IO.puts("received #{msg}")
end
```

Processes names must follow some rules

* The name can only be an atom.
* A single process can have only one name.
* Two processes can’t have the same name.

## Runtime considerations

* Although multiple processes may run in parallel, a single process is always sequential — it either runs some code or waits for a message. If many processes send messages to a single process, that single process can significantly affect overall throughput.
* The mailbox size is limited by available memory. Thus, if a process constantly falls behind, meaning messages arrive faster than the process can handle them, the mailbox will constantly grow and increasingly consume memory. Ultimately, a single slow process may cause an entire system to crash by consuming all the available memory.
* As already mentioned, processes share no memory. Thus, sending a message to another process results in a deep copy of the message contents. having many processes frequently send big messages may affect system performance. The notion of small versus big is subjective. Simple data, such as a number, an atom, or a tuple with few elements, is obviously small. A list of a million complex structures is big. The border lies somewhere in between and depends on your specific case.
* Each BEAM scheduler is in reality an OS thread that manages the execution of BEAM processes. By default, BEAM uses only as many schedulers as there are logical processors available.

## Summary

* A BEAM process is a lightweight concurrent unit of execution. Processes are completely isolated and share no memory.
* Processes can communicate with asynchronous messages. Synchronous sends and responses are manually built on top of this basic mechanism.
* A server process is a process that runs for a long time (possibly forever) and handles various messages. Server processes are powered by endless recursion.
* Server processes can maintain their own private state using the arguments of the endless recursion.
